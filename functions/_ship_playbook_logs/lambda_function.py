# Copyright 2018 Twilio, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License

from typing import List
import boto3
import gzip
import json
import base64
import io
import uuid
import os
from dataclasses import dataclass

SOCLESS_LOGS_BUCKET = os.environ["SOCLESS_LOGS"]


@dataclass
class LogsPayload:
    """
    {
        'messageType': 'DATA_MESSAGE',
        'owner': '1234567890',
        'logGroup': '/socless/playbook-execution-logs',
        'logStream': 'states/TestStepFunction/2021-01-07-19/c1234567a8',
        'subscriptionFilters': ['socless-sandbox-SavePlaybookExecutionLogsLogsSubscriptionFilterCloudWatchLog1-HASLDFKJA'],
        'logEvents': [
            {
                'id': '1234567',
                'timestamp': 1610049273165,
                'message': '{"id":"1","type":"ExecutionStarted","details":{"roleArn":"arn:aws:iam::1234567890:role/socless-sandbox-states-execution"},"previous_event_id":"0","event_timestamp":"1610049273165","execution_arn":"arn:aws:states:us-west-1:1234567890:execution:TestStepFunction:12345-cfa1234-234-123af"}'
            },
            ...
        ]
    }
    """

    messageType: str
    owner: str
    logGroup: str
    logStream: str
    subscriptionFilters: List[str]
    logEvents: List[dict]


def convert_nested_json_strings(event):
    """
    Converts Json nested as strings in the event to python dictionaries
    Args:
        event (dict): A single event from a Step Functions Cloudwatch Log
    Returns:
        (dict) : A new dictionary of the event but with nested json strings
                converted to dictionaries too
    """
    converted_event = {}
    for key, value in event.items():
        if isinstance(value, str):
            converted_event[key] = json.loads(value)
        else:
            converted_event[key] = value
    return converted_event


def extract_execution_id(event):
    """
    Extracts the execution ID from a single event

    Args:
        event (dict): A single event from a Step Functions Cloudwatch Log
    """
    converted_event = convert_nested_json_strings(event)
    execution_arn = converted_event["message"]["execution_arn"]
    execution_id = execution_arn.split(":")[-1]
    return execution_id


def ship_log_contents(contents: bytes, location: str):
    """
    Sends log file contents to S3

    Args:
        contents (bytes): Logfile contents generated by generate_logfile_content function
        location (str): desired S3 object path
    """

    with io.BytesIO(contents) as f:
        s3 = boto3.client("s3")
        s3.put_object(Body=f, Bucket=SOCLESS_LOGS_BUCKET, Key=location)


def construct_object_key(logs_payload: LogsPayload) -> str:
    """
    Constructs the object path for the log in the SOCless logs bucket

    Args:
        payload: An uncompressed CW Logs payload of an AWS Step Functions Log entry
    Returns:
        str: An object key of the form playbook_executions/{playbook_name}/{date}/{execution_id}/{uuid}
    """
    log_type = "playbook_executions"
    _, playbook_name, date_and_hour, _ = logs_payload.logStream.split("/")
    execution_id = extract_execution_id(logs_payload.logEvents[0])

    object_key = "/".join(
        [
            f"{log_type}",
            f"{playbook_name}",
            f"{date_and_hour}",
            f"{execution_id}",
            f"{uuid.uuid4()}",
        ]
    )

    # playbook_executions/TestPlaybook/2021-01-07-19/c3123-123/2dcf-6152
    return object_key


def uncompress_payload(cw_event: dict) -> dict:
    """Uncompresses a Cloudwatch log event and turns it into a dict.

    Args:
        cw_event: Dict containing base64 encoded and zipped logs entry
            delivered by Cloudwatch Logs subscription
    Returns:
        (dict): uncompressed logs data
    """
    cw_data = cw_event["awslogs"]["data"]

    compressed_payload = base64.b64decode(cw_data)
    uncompressed_payload = gzip.decompress(compressed_payload)
    return json.loads(uncompressed_payload)


def extract_metadata(logs_payload: LogsPayload) -> dict:
    """Extracts top-level metadata from the Cloudwatch payload so that
    it can be added to each log entry.

    Args:
        payload: Uncompressed payload representing Cloudwatch logs data for
            Step Functions State Machine logs
    Returns:
        (dict): Metadata that will be added to each log entry
    """
    return {
        "account": logs_payload.owner,
        "log_stream": logs_payload.logStream,
        "log_group": logs_payload.logGroup,
    }


def generate_logfile_content(logs_payload: LogsPayload, metadata: dict) -> bytes:
    transformed_log_events: List[str] = [
        json.dumps({**metadata, **convert_nested_json_strings(event)})
        for event in logs_payload.logEvents
    ]

    logfile_contents = "\n".join(transformed_log_events).encode("utf-8")
    return logfile_contents


def lambda_handler(event: dict, context):
    """Decode StepFunctions Logs payload, transform it and save to s3.

    Args:
        event: {'awslogs': {'data': '<base_64_encoded_string>'}}
    """
    # decompress and format payload for processing
    uncompressed_payload = uncompress_payload(event)
    logs_payload = LogsPayload(**uncompressed_payload)

    # transform logs for ingestion
    object_key = construct_object_key(logs_payload)
    metadata = extract_metadata(logs_payload)
    logfile_contents = generate_logfile_content(logs_payload, metadata)

    ship_log_contents(contents=logfile_contents, location=object_key)
    print(f"uploaded logs {object_key}")

    return object_key
